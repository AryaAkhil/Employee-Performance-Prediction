{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Fastai_Employee_Performance_Prediction.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"x3YZdAoQO5eF"},"source":["# Employee performance prediction using Fastai\n","\n","This python script aims to predict employee performance flag using 1731 data points originally provided."]},{"cell_type":"markdown","metadata":{"id":"9T3cYEAVYhVa"},"source":["## Install relevant packages\n","\n","If users are using google colab, except fastai upagrade, rest of the packages mentioned in the \"Data Import\" section below are installed by default. In your local machine you might have to install these packages as per your prior usage of python - \n","1. pandas\n","2. numpy\n","3. os\n","4. fastai\n","5. seaborn\n","6. imblearn\n","7. metrics\n","8. matlplotlib"]},{"cell_type":"code","metadata":{"id":"6LejkSOFRGpS"},"source":["#!pip install fastai\n","#!pip install fastai --upgrade"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tb2MpnAxQIks"},"source":["## Import libraries"]},{"cell_type":"code","metadata":{"id":"gNi1IH-dPujB"},"source":["from google.colab import drive\n","import pandas as pd\n","import os\n","from scipy import mean\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import accuracy_score, fbeta_score, cohen_kappa_score, roc_auc_score, confusion_matrix, precision_score,make_scorer\n","from imblearn.over_sampling import BorderlineSMOTE\n","from fastai import *\n","from fastai.tabular.all import *\n","import warnings\n","warnings.filterwarnings('ignore')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mLM_4yadRf2w"},"source":["## Set working directory\n","\n","If you are using google colab, place the csv input file in your google directory and the next 3 lines of code should do the magic. Else,if you are using your own local machine, coment the first line of code in below cell and just replace the root_dir below with your local working directory to set."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ufDEQFMHRSkH","executionInfo":{"status":"ok","timestamp":1621931963512,"user_tz":-330,"elapsed":1373,"user":{"displayName":"ARYA AKHIL _","photoUrl":"","userId":"03888002519836551564"}},"outputId":"a128cdc7-f199-4970-f8fc-21537fbc5815"},"source":["drive.mount('/content/gdrive', force_remount=True)\n","root_dir = \"/content/gdrive/MyDrive/Colab_Notebooks/Fastai_Tabular_Classification\"\n","os.chdir(root_dir)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"39gFjC-qQxMT"},"source":["**Note to users: Make sure to create a new folder in your working directory named \"Fastai_Saved_Models\".**"]},{"cell_type":"markdown","metadata":{"id":"P_pkwS7-Pq4G"},"source":["## Data Import"]},{"cell_type":"code","metadata":{"id":"vg9me5GORgEC"},"source":["df = pd.read_csv(\"Input.csv\")\n","df.head(3)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ulZsp9GPkrff"},"source":["## Data pre-processing"]},{"cell_type":"markdown","metadata":{"id":"1VmaeScFVnS8"},"source":["\n","Data cleaning has already been taken care. Given the nature of the problem, dropping irrelevant columns \n","'Person_ID','Name','Type_ID','Service','Group','Group_ID','Score'"]},{"cell_type":"code","metadata":{"id":"TH33066tVGIp"},"source":["df_model = df.drop(columns = ['Person_ID','Name','Type_ID','Service','Group','Group_ID','Score'])\n","df_model.head(3)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WwOxHgTZm30r"},"source":["## Borderline SMOTEing\n","\n","Documentation - https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.BorderlineSMOTE.html\n","\n","Reference article - https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/\n","\n","\n","**Note to users: \n","Users of this notebook don't need to run the below code cell. This cell was used during model training. Best model has been shared as \".h5\" file that can be loaded and made to predict on desired period in \"User-section\" of the notebook later.**"]},{"cell_type":"code","metadata":{"id":"ZqZ6YFtlm5mm"},"source":["def borderline_sample(train_valid):\n","  \n","  # save the list of train_valid column names\n","  clmns = list(train_valid.columns)\n","\n","  # after separate multiple iterations of testing , k=3 and m = 4 were best hyperparameters for our data\n","  oversample = BorderlineSMOTE(k_neighbors=3,m_neighbors=8)\n","\n","  # split into X and y\n","  X_train_valid = train_valid.drop(columns='Class')\n","  y_train_valid = train_valid['Class']\n","  X_train_valid, y_train_valid = oversample.fit_resample(X_train_valid, y_train_valid)\n","\n","  # join back again\n","  train_valid = pd.DataFrame(np.concatenate((y_train_valid.reshape(-1,1),X_train_valid), axis=1))\n","\n","  # rename target column\n","  train_valid.columns = clmns\n","\n","  return train_valid"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eYeSF8cSgYmi"},"source":["## Data preparation"]},{"cell_type":"code","metadata":{"id":"b-lX-Fe-g2cl"},"source":["# prepare train data for training\n","def prepare_train_data(df_model,p):\n","  \n","  # define train and test set in each iteration of training\n","  train_valid = df_model[df_model['Period']<=p]\n","  train_valid = train_valid.drop(columns='Period')\n","\n","  # SMOTEing\n","  #train_valid = borderline_sample(train_valid)\n","\n","  # SMOTEing disturbs data type of objects, hence fixing them\n","  train_valid['Class'] = train_valid['Class'].astype('int')\n","  train_valid['Class'] = train_valid['Class'].astype('category')\n","  train_valid = train_valid.infer_objects()\n","\n","  # split criterion - 80% train and 20% test\n","  cond = (train_valid.index<=round(0.80*len(train_valid)))\n","\n","  # get indices of train and valid\n","  train_idx = np.where( cond)[0]\n","  valid_idx = np.where(~cond)[0]\n","\n","  # create list of train and valid index, call it splits\n","  splits = (list(train_idx),list(valid_idx))\n","\n","  return train_valid, splits\n","\n","# prepare test data for evaluation\n","def prepare_test_data(df_model,p):\n","  \n","  # define test set in each iteration of evaluation\n","  test = df_model[df_model['Period']==p]\n","\n","  # split data into train and test as per each iteration\n","  X_test = test.iloc[:,2:]\n","  y_test = test.iloc[:,1]\n","\n","  return X_test,y_test"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BDJoaiUH2KLF"},"source":["## Model Definition\n","\n","Documentation for autokeras - https://course.fast.ai/videos/?lesson=1\n","**Note to users: \n","Users of this notebook don't need to run the below code cell. This cell was used during model training. Best model has been shared as \".h5\" file that can be loaded and made to predict on desired period in \"User-section\" of the notebook later.**"]},{"cell_type":"code","metadata":{"id":"xmC9dBUNoW6z"},"source":["def fastai_classifier(train_valid,splits):\n","  \n","  # define target\n","  dep_var = 'Class'\n","\n","  # define categorical and continuous variables split\n","  cont_nn,cat_nn = cont_cat_split(train_valid, dep_var=dep_var)\n","\n","  # define data preprocessing steps - although not needed in this use cases\n","  procs = [FillMissing, Categorify, Normalize]\n","\n","  # define tabular pandas object and load it to data loaders\n","  to_nn = TabularPandas(train_valid, procs, cat_nn, cont_nn, splits=splits, y_names=dep_var, y_block = CategoryBlock())\n","  dls = to_nn.dataloaders()\n","\n","  # define model\n","  model = tabular_learner(dls, layers=[20,50,100,150], metrics=[accuracy, error_rate, Recall(), Precision(),APScoreBinary()])\n","\n","  # find optimum learning rate if fine tuning seems necessary\n","  _, lr_steepest = model.lr_find()\n","\n","    # define callbacks list\n","  #callbacks = [EarlyStoppingCallback(model, min_delta=1e-5, patience=3),SaveModelCallback(model)]\n","\n","  # add callbacks\n","  #model.callbacks = callbacks\n","\n","  # fit model\n","  model.unfreeze()\n","  model.fit_one_cycle(3,slice(lr_steepest),cbs=SaveModelCallback()) \n","\n","  # fine tune\n","  model.fine_tune(2)\n","\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ah5MAxlez28E"},"source":["## Model Run\n","\n","**Note to users: \n","Users of this notebook don't need to run the below code cell. This cell was used during model training. Best model has been shared as \".h5\" file that can be loaded and made to predict on desired period in \"User-section\" of the notebook later.**"]},{"cell_type":"code","metadata":{"id":"k4IJmn5wyw2F"},"source":["# Shift data and train model. As data is time sensitive, need to find the best model\n","for p in range(3,4):\n","  \n","  # prepare data for current iteration - if you want to disable SMOTEing go to prepare_train_data function and comment it out\n","  train_valid, splits = prepare_train_data(df_model,p)\n","  \n","  # fit model\n","  model = fastai_classifier(train_valid,splits)\n","\n","  # save the best performing model to file\n","  model.export('Fastai_Saved_Models/Model trained upto period ' + str(p) + '.pkl')\n","\n","  # print training iteration\n","  print('Trained period upto= ',p)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yf3h7jX5uPE1"},"source":["## Model Evaluation\n","\n","**Note to users: \n","Users of this notebook don't need to run the below code cell. This cell was used during model training. Best model has been shared as \".h5\" file that can be loaded and made to predict on desired period in \"User-section\" of the notebook later.**"]},{"cell_type":"code","metadata":{"id":"wSD7jDj-pfsd"},"source":["# define a mean precision score dictionary at model level to evaluate best model\n","mean_prec_dict = {}\n","\n","# load all models one by one\n","for mdl in range(3,7):\n","\n","  # load model\n","  model = load_learner('Fastai_Saved_Models/Model trained upto period ' + str(mdl) + '.pkl')\n","\n","  # forward chaining evaluation\n","  for p in range(mdl+1,26):\n","\n","      # define primary evaluation dictionary\n","      prec_dict = {}\n","\n","      # prepare test data for each iteration\n","      X_test,y_test = prepare_test_data(df_model,p)\n","\n","      # predict on test - this predicts probabilities\n","      dl = model.dls.test_dl(X_test)\n","      pred = model.get_preds(dl=dl)\n","      y_pred = pred[0][:,0] # this is done b/c fastai produces a tensor, need to convert to array\n","\n","      # convert probabilities to classes using default threshold = 0.5\n","      y_hat = np.where(y_pred > 0.5, 1, 0)\n","\n","      # f beta score, beta = 0.5 to inc rease weightage to precision - want to reduce false +ve\n","      prec = precision_score(y_test, y_hat)\n","\n","      # store scores in a dictionary\n","      prec_dict['mdl=' + str(mdl) + '_test_p=' + str(p)] = prec\n","      #print(prec_dict)\n","\n","  # mean score of precision for a model across 24 period of evaluation\n","  mean_prec_dict['Model=' + str(mdl)] = list(map(lambda x: mean(prec_dict[x]), prec_dict))\n","\n","mean_prec_dict"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zuAAsp02ZqNL"},"source":["## User section - load best model and predict"]},{"cell_type":"markdown","metadata":{"id":"VOkJi1HYX3pi"},"source":["After running the above two cells of code we obtain some insights on the performance of different models over different test sets. Based on the observations on model no. and mean precision score, model-6 had the highest mean precision score of all models, hence selecting it to be the final model.\n","User can run the below cell to load model-6 from working directory and predict on any period they like. Model-6 is shared as separate \".h5\" file. Make sure it is present in your working directory.\n","\n","Model-6 is trained using first 6 periods only, yet it yielded highest mean precision score. This indicates a seasonal behaviour in data and that data is indeed time sensitive."]},{"cell_type":"code","metadata":{"id":"0FKqPk9NSBFV"},"source":["# load model\n","m = 6\n","model = load_learner('Fastai_Saved_Models/Model trained upto period ' + str(m) + '.pkl')\n","\n","# prepare test for period 25 and onwards - just change p to whichever period you want to predict. Make sure to not disturb the format of ML_Input.csv file.\n","p = 7\n","X_test,y_test = prepare_test_data(df_model,p)\n","\n","# predict on test - this predicts probabilities\n","dl = model.dls.test_dl(X_test)\n","pred = model.get_preds(dl=dl)\n","y_pred = pred[0][:,0] # this is done b/c fastai produces a tensor, need to convert to array\n","\n","# convert probabilities to classes using default threshold = 0.5\n","y_hat = np.where(y_pred > 0.5, 1, 0)\n","\n","# confusion matrix of trained model\n","#print('confusion matrix of trained model')\n","#interpret = ClassificationInterpretation.from_learner(model)\n","#interpret.plot_confusion_matrix()\n","\n","# plot confusion matrix\n","cm=confusion_matrix(y_test,y_hat)\n","ax= plt.subplot()\n","sns.heatmap(cm, annot=True, fmt='g', ax=ax)\n","ax.set_xlabel('Predicted labels')\n","ax.set_ylabel('True labels')\n","ax.set_title('Confusion Matrix')\n","ax.xaxis.set_ticklabels(['Low P','High P'])\n","ax.yaxis.set_ticklabels(['Low P','High P'])\n","\n","# precision score\n","prec = precision_score(y_test, y_hat)\n","print(\"Precision: \", round(prec*100,2), \"%\")\n","\n","# accuracy\n","acc = accuracy_score(y_test, y_hat)\n","print(\"Accuracy: \", round(acc*100,2), \"%\")\n","\n","# cohen kappa score\n","kappa = cohen_kappa_score(y_test, y_hat)\n","print(\"Kappa: \", round(kappa*100,2), \"%\")\n","\n","# f beta score, beta = 0.5 to increase weightage to precision - want to reduce false +ve\n","f_beta = fbeta_score(y_test, y_hat,beta=0.5)\n","print(\"F-0.5: \", round(f_beta*100,2), \"%\")\n","\n","# roc score\n","auc = roc_auc_score(y_test, y_hat) \n","print(\"AUC: \", round(auc*100,2), \"%\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"95vA5vD5o9cq"},"source":["# END"]}]}